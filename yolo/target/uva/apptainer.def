Bootstrap: docker
From: nvidia/cuda:12.8.0-cudnn-devel-ubuntu24.04

%environment
    export DEBIAN_FRONTEND=noninteractive
    export PATH="/usr/local/cuda/bin:/usr/local/bin:/opt/venv/bin:${PATH}"
    export LD_LIBRARY_PATH="/usr/local/cuda/lib64:${LD_LIBRARY_PATH}"
    # chocolatechip is pip-installed, so no PYTHONPATH needed unless you want overrides

%post
    set -eux

    apt-get update && apt-get install -y --no-install-recommends \
        build-essential git libopencv-dev file cmake \
        python3-pip python3-venv fio wget ca-certificates \
        && rm -rf /var/lib/apt/lists/*

    # venv
    python3 -m venv /opt/venv
    . /opt/venv/bin/activate
    pip install --no-cache-dir --upgrade pip

    # core python deps you used in docker
    pip install --no-cache-dir \
        pycocotools imagesize cloudmesh-common \
        git+https://github.com/cloudmesh/cloudmesh-gpu.git

    # --- install chocolatechip from GitHub ---
    pip install --no-cache-dir \
        git+https://github.com/jpfleischer/chocolatechip.git

    # --- fetch darknet build script into image ---
    wget -O /usr/local/bin/build_darknet.sh \
        "https://raw.githubusercontent.com/jpfleischer/chocolatechip/refs/heads/main/semester-work/spring2025/darknet/artifacts/build_darknet.sh"
    chmod +x /usr/local/bin/build_darknet.sh

    # writable defaults (binds will overlay)
    mkdir -p /outputs /workspace/.cache/splits /workspace
    chmod 777 /outputs /workspace /workspace/.cache/splits || true

%runscript
#!/bin/bash
set -euo pipefail

echo "Running on $(hostname)"
echo "CUDA_VISIBLE_DEVICES=${CUDA_VISIBLE_DEVICES:-}"
echo "Args: $*"

# Build darknet inside the bind-mounted /host_workspace
/usr/local/bin/build_darknet.sh

# If the user passed a command, run it.
if [ "$#" -gt 0 ]; then
    exec "$@"
fi

# Otherwise run a sensible default:
exec python -u -m chocolatechip.model_training.train \
    --profile FisheyeTrafficDarknetLocal

